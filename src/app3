#!/usr/bin/python3
# -*- coding: utf-8 -*-

# built ins
import asyncio
from asyncio import Queue
import os
import signal
import sys
from random import sample

import json,orjson
import redis
import redis.asyncio as redis
#import signal
#from multiprocessing import Manager
#from multiprocessing.queues import Queue
#from multiprocessing import cpu_count
#from aiomultiprocess import Pool
import tomli
import uvloop
# installed
from loguru import logger as log

asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())


from configuration.label_numbering import get_now_unix_time
from data_cleaning.app_data_cleaning import reconciling_size
from market_understanding.scanning_volume_spike import scanning_volume
from messaging.telegram_bot import telegram_bot_sendtext
from strategies.app_future_spreads import future_spreads
from strategies.app_hedging_spot import hedging_spot
from strategies.relabelling_trading_result import relabelling_trades
from transaction_management.deribit.api_requests import SendApiRequest
from transaction_management.deribit.avoiding_double_ids import \
    avoiding_double_ids
from transaction_management.deribit.cancelling_active_orders import \
    cancelling_orders
from transaction_management.deribit.data_producer import StreamingAccountData
from transaction_management.deribit.managing_deribit import ModifyOrderDb
from transaction_management.deribit.running_strategies import \
    executing_strategies
from transaction_management.deribit.saving_result import saving_ws_data
from transaction_management.deribit.capturing_user_changes import \
    saving_and_relabelling_orders
from utilities.caching import combining_order_data
from utilities.caching import combining_ticker_data as cached_ticker
from utilities.caching import update_cached_orders, update_cached_ticker
from utilities.system_tools import (SignalHandler, async_raise_error_message,
                                    parse_error_message, provide_path_for_file,
                                    raise_error_message)


def handle_ctrl_c(
    signum, 
    stack_frame
    )->None:
    
    sys.exit(0)
    
                  
signal_handler = SignalHandler()

async def main2():
    
    """
        https://blog.finxter.com/python-multiprocessing-pool-ultimate-guide/

    """
    
    sub_account_id = "deribit-148510"
    
    try:
        
        queue: Queue = Manager().Queue()
        
        #processes = max(1,int (cpu_count() / 4) - 1)
        
        #maxtasksperchild=1
        
        stream = StreamAccountData(sub_account_id)
       
        producer_task = asyncio.create_task(stream.ws_manager(queue)) 
        
#        async with Pool(maxtasksperchild=2) as pool:
        async with Pool() as pool:

            while signal_handler.KEEP_PROCESSING:
       
                executing_strategies_tasks = [
                    asyncio.create_task(pool.apply(
                        executing_strategies, 
                        args=(sub_account_id,
                              queue
                              )
                        ))
                    ]
       
                await asyncio.gather(
                    *executing_strategies_tasks,
       
                    )
                
                await asyncio.sleep(0.0005)

                await producer_task
                
                pool.close()
                
                await pool.join()
            
    except Exception as error:
        log.critical (error)
        
        await async_raise_error_message(
            error,
            "WebSocket connection - failed to distribute_incremental_ticker_result_as_per_data_type",
        )
        


def get_config(file_name: str) -> list:
    """ """
    
    config_path = provide_path_for_file (file_name)
    
    try:
        if os.path.exists(config_path):
            with open(config_path, "rb") as handle:
                read= tomli.load(handle)
                return read
    except:
        return []


async def handle_notification(client_redis,
                              CHANNEL_NAME):

    pubsub = client_redis.pubsub()   
      
    await pubsub.subscribe(CHANNEL_NAME)
    
    while True:
    
        try:
            message = await pubsub.get_message()

            if message["type"] == "message":
                payload = orjson.loads(message["data"])

                log.warning (f"{CHANNEL_NAME}, {payload["user_id"]}, {payload["message"]}")
                
        except:
            continue

        finally:
            await asyncio.sleep(.001) 


async def main():
    
    sub_account_id = "deribit-148510"

    # registering strategy config file    
    file_toml = "config_strategies.toml"
    
    #server_time_fixed = get_now_unix_time()  

    idle_time = 1
    
    CHANNEL_NAME = "notification"
    
    try:

        private_data: str = SendApiRequest(sub_account_id)

        modify_order_and_db: object = ModifyOrderDb(sub_account_id)
        
        client_redis = redis.Redis()

        #time_elapsed = (server_time - server_time_fixed)/1000
        
        #if time_elapsed > 15 * 60 :
            
            #pass
                            
        #await asyncio.sleep(idle_time)
            
        # parsing config file
        config_app = get_config(file_toml)

        queue = Queue(maxsize=1)
        queue_general, queue_cancelling, queue_capturing_user_changes = Queue(), Queue(), Queue()
        queue_avoiding_double, queue_hedging, queue_combo  = Queue(), Queue(), Queue()
        queue_redis=Queue()
        
        stream = StreamingAccountData(sub_account_id)
                
        producer_task = asyncio.create_task(
            stream.ws_manager(
                config_app,
                queue_general)
            ) 
        saving_task = asyncio.create_task(
            saving_ws_data(
                private_data,
                modify_order_and_db,
                client_redis,
                           config_app,
                queue_general,
                queue_cancelling,
                queue_capturing_user_changes,
                queue_avoiding_double,
                queue_hedging,
                queue_combo,
                queue_redis)
            ) 
        
        await asyncio.sleep(0.0005)
        
        """
                            
            #scanning_volume()
                    
            """
            
        await asyncio.gather(
            producer_task, 

            saving_task,
            
            handle_notification(
                client_redis,
                CHANNEL_NAME),
          
            cancelling_orders(
                private_data,
                modify_order_and_db,
                client_redis,
                config_app
                ),    
        #main_redis(queue_redis),    
            
            )  

        await queue.join()
        

    except Exception as error:
        
        parse_error_message(error)
        await telegram_bot_sendtext (
            f"app-{error}",
            "general_error"
            )


if __name__ == "__main__":
    
    
    try:
        signal.signal(signal.SIGINT, handle_ctrl_c) # terminate on ctrl-c
        
        uvloop.run(main())
        
    except(
        KeyboardInterrupt, 
        SystemExit
        ):
        
        asyncio.get_event_loop().run_until_complete(main())
        
    except Exception as error:
        parse_error_message(error)
        
        asyncio.run(telegram_bot_sendtext (
            error,
            "general_error"
            ))
